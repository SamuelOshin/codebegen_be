"""
GitHub deployment and generation comparison services.
"""

import difflib
import os
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import logging

from app.schemas.generation import (
    GitHubDeploymentRequest, GitHubDeploymentResponse,
    GenerationComparisonRequest, GenerationComparisonResponse,
    FileComparison
)
from app.services.file_manager import file_manager
from app.services.github_service import github_service

logger = logging.getLogger(__name__)


class GitHubDeploymentService:
    """Service for deploying generations to GitHub with advanced features."""
    
    def __init__(self):
        self.ci_cd_templates = {
            "fastapi": {
                "workflow_file": ".github/workflows/ci.yml",
                "content": self._get_fastapi_workflow()
            },
            "react": {
                "workflow_file": ".github/workflows/ci.yml", 
                "content": self._get_react_workflow()
            },
            "django": {
                "workflow_file": ".github/workflows/ci.yml",
                "content": self._get_django_workflow()
            }
        }
    
    async def deploy_to_github(
        self, 
        generation_id: str, 
        request: GitHubDeploymentRequest
    ) -> GitHubDeploymentResponse:
        """Deploy generation to GitHub with advanced deployment options."""
        
        try:
            # Get generation files
            generation_dir = await file_manager.get_generation_directory(generation_id)
            if not generation_dir or not generation_dir.exists():
                raise ValueError("Generation files not found")
            
            # Create GitHub repository
            repo_info = await github_service.create_repository(
                access_token=request.github_token,
                repo_name=request.repo_name,
                description=request.description or "Generated by CodebeGen",
                private=request.private
            )
            
            # Prepare files for deployment
            files_to_deploy = await self._prepare_deployment_files(
                generation_dir, request
            )
            
            # Upload files to repository
            success = await github_service.upload_files_to_repo(
                access_token=request.github_token,
                owner=repo_info["owner"]["login"],
                repo_name=request.repo_name,
                files=files_to_deploy,
                branch=request.branch_name,
                commit_message=request.commit_message
            )
            
            if not success:
                raise ValueError("Failed to upload files to GitHub")
            
            # Get commit SHA
            commit_sha = await self._get_latest_commit_sha(
                request.github_token, 
                repo_info["owner"]["login"], 
                request.repo_name,
                request.branch_name
            )
            
            # Setup deployment if needed
            deployment_url = None
            if request.deployment_type == "pages":
                deployment_url = await self._setup_github_pages(
                    request.github_token,
                    repo_info["owner"]["login"],
                    request.repo_name
                )
            elif request.deployment_type == "vercel":
                deployment_url = await self._setup_vercel_deployment(
                    repo_info["html_url"]
                )
            
            return GitHubDeploymentResponse(
                success=True,
                repository_url=repo_info["html_url"],
                clone_url=repo_info["clone_url"],
                deployment_url=deployment_url,
                branch=request.branch_name,
                commit_sha=commit_sha,
                ci_cd_configured=request.include_ci_cd,
                message="Project successfully deployed to GitHub"
            )
            
        except Exception as e:
            logger.error(f"GitHub deployment failed: {e}")
            return GitHubDeploymentResponse(
                success=False,
                repository_url="",
                clone_url="",
                branch="",
                message=f"Deployment failed: {str(e)}"
            )
    
    async def _prepare_deployment_files(
        self, 
        generation_dir: Path, 
        request: GitHubDeploymentRequest
    ) -> Dict[str, str]:
        """Prepare files for deployment with additional configurations."""
        
        # Get all generated files
        files = {}
        for file_path in generation_dir.rglob('*'):
            if file_path.is_file():
                relative_path = file_path.relative_to(generation_dir)
                try:
                    content = file_path.read_text(encoding='utf-8')
                    files[str(relative_path)] = content
                except UnicodeDecodeError:
                    # Skip binary files
                    continue
        
        # Add CI/CD configuration if requested
        if request.include_ci_cd:
            ci_cd_config = self._detect_project_type_and_get_cicd(files)
            if ci_cd_config:
                files[ci_cd_config["workflow_file"]] = ci_cd_config["content"]
        
        # Add deployment-specific files
        if request.deployment_type == "pages":
            files.update(self._get_github_pages_files())
        elif request.deployment_type == "vercel":
            files.update(self._get_vercel_config_files())
        
        # Add README deployment instructions
        readme_path = "README.md"
        if readme_path in files:
            files[readme_path] = self._enhance_readme_with_deployment_info(
                files[readme_path], request
            )
        else:
            files[readme_path] = self._create_deployment_readme(request)
        
        return files
    
    def _detect_project_type_and_get_cicd(self, files: Dict[str, str]) -> Optional[Dict[str, str]]:
        """Detect project type and return appropriate CI/CD configuration."""
        
        # Check for FastAPI
        if any("fastapi" in content.lower() for content in files.values()):
            return self.ci_cd_templates["fastapi"]
        
        # Check for React
        if "package.json" in files:
            package_content = files["package.json"]
            if "react" in package_content.lower():
                return self.ci_cd_templates["react"]
        
        # Check for Django
        if any("django" in content.lower() for content in files.values()):
            return self.ci_cd_templates["django"]
        
        return None
    
    def _get_fastapi_workflow(self) -> str:
        """Get FastAPI CI/CD workflow configuration."""
        return """name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run tests
      run: |
        pytest
    
    - name: Run linting
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
  
  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to production
      run: |
        echo "Add your deployment steps here"
        # Example: Deploy to Heroku, AWS, etc.
"""
    
    def _get_react_workflow(self) -> str:
        """Get React CI/CD workflow configuration."""
        return """name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Run tests
      run: npm test -- --coverage --watchAll=false
    
    - name: Build application
      run: npm run build
  
  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./build
"""
    
    def _get_django_workflow(self) -> str:
        """Get Django CI/CD workflow configuration."""
        return """name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run tests
      env:
        DATABASE_URL: postgres://postgres:postgres@localhost:5432/test_db
      run: |
        python manage.py test
  
  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to production
      run: |
        echo "Add your deployment steps here"
"""
    
    def _get_github_pages_files(self) -> Dict[str, str]:
        """Get GitHub Pages specific configuration files."""
        return {
            ".github/workflows/pages.yml": """name: Deploy to GitHub Pages

on:
  push:
    branches: [ main ]

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Build
      run: npm run build
    
    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./dist
""",
            "CNAME": ""  # Will be filled if custom domain is specified
        }
    
    def _get_vercel_config_files(self) -> Dict[str, str]:
        """Get Vercel deployment configuration files."""
        return {
            "vercel.json": """{
  "version": 2,
  "builds": [
    {
      "src": "*.py",
      "use": "@vercel/python"
    }
  ],
  "routes": [
    {
      "src": "/(.*)",
      "dest": "/app.py"
    }
  ]
}""",
            ".vercelignore": """__pycache__/
*.pyc
.env
.git/
.venv/
venv/
node_modules/
"""
        }
    
    async def _get_latest_commit_sha(
        self, 
        token: str, 
        owner: str, 
        repo: str, 
        branch: str
    ) -> Optional[str]:
        """Get the latest commit SHA from GitHub."""
        try:
            # This would use GitHub API to get commit SHA
            # For now, return a placeholder
            return "placeholder_commit_sha"
        except Exception:
            return None
    
    async def _setup_github_pages(
        self, 
        token: str, 
        owner: str, 
        repo: str
    ) -> Optional[str]:
        """Setup GitHub Pages for the repository."""
        try:
            # This would configure GitHub Pages via API
            return f"https://{owner}.github.io/{repo}"
        except Exception:
            return None
    
    async def _setup_vercel_deployment(self, repo_url: str) -> Optional[str]:
        """Setup Vercel deployment for the repository."""
        try:
            # This would trigger Vercel deployment
            return "https://your-project.vercel.app"
        except Exception:
            return None
    
    def _enhance_readme_with_deployment_info(
        self, 
        existing_readme: str, 
        request: GitHubDeploymentRequest
    ) -> str:
        """Enhance existing README with deployment information."""
        
        deployment_section = f"""

## 🚀 Deployment

This project has been configured for deployment on GitHub.

### Repository Information
- **Repository**: {request.repo_name}
- **Branch**: {request.branch_name}
- **Deployment Type**: {request.deployment_type}

### Getting Started
1. Clone the repository:
   ```bash
   git clone <repository-url>
   cd {request.repo_name}
   ```

2. Install dependencies (see installation instructions above)

3. Run the application (see usage instructions above)

### CI/CD
{"CI/CD pipeline has been configured with GitHub Actions." if request.include_ci_cd else "No CI/CD pipeline configured."}

### Deployment
- **Type**: {request.deployment_type.title()}
{"- **Pages URL**: Will be available after first deployment" if request.deployment_type == "pages" else ""}
{"- **Vercel URL**: Will be available after connecting to Vercel" if request.deployment_type == "vercel" else ""}

---
*Generated and deployed by [CodebeGen](https://codebegen.ai)*
"""
        
        return existing_readme + deployment_section
    
    def _create_deployment_readme(self, request: GitHubDeploymentRequest) -> str:
        """Create a new README with deployment information."""
        return f"""# {request.repo_name.title()}

{request.description or "A project generated by CodebeGen"}

## 🚀 Quick Start

### Prerequisites
- Ensure you have the required runtime installed (Node.js, Python, etc.)

### Installation
1. Clone the repository:
   ```bash
   git clone <repository-url>
   cd {request.repo_name}
   ```

2. Install dependencies:
   ```bash
   # For Node.js projects
   npm install
   
   # For Python projects
   pip install -r requirements.txt
   ```

### Usage
```bash
# For Node.js projects
npm start

# For Python projects
python main.py
```

## 📋 Project Structure

This project was generated using CodebeGen and includes:
- Automated code generation
- Best practices implementation
- Ready-to-deploy configuration

## 🛠️ Deployment

### Repository Information
- **Branch**: {request.branch_name}
- **Deployment Type**: {request.deployment_type}

### CI/CD
{"✅ CI/CD pipeline configured with GitHub Actions" if request.include_ci_cd else "❌ No CI/CD pipeline configured"}

### Live Deployment
{"- GitHub Pages: Available after first push to main branch" if request.deployment_type == "pages" else ""}
{"- Vercel: Connect this repository to Vercel for automatic deployments" if request.deployment_type == "vercel" else ""}

## 📝 License

This project is generated by CodebeGen. Please check individual components for their respective licenses.

---
*Generated by [CodebeGen](https://codebegen.ai)*
"""


class GenerationComparisonService:
    """Service for comparing two generations."""
    
    def __init__(self):
        self.max_diff_lines = 100
        self.binary_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.zip', '.pdf'}
    
    async def compare_generations(
        self,
        generation_1_id: str,
        generation_2_id: str,
        request: GenerationComparisonRequest
    ) -> GenerationComparisonResponse:
        """Compare two generations and return detailed analysis."""
        
        try:
            # Get files from both generations
            files_1 = await file_manager.get_project_files(generation_1_id)
            files_2 = await file_manager.get_project_files(generation_2_id)
            
            if not files_1:
                raise ValueError(f"Generation {generation_1_id} files not found")
            if not files_2:
                raise ValueError(f"Generation {generation_2_id} files not found")
            
            # Perform comparison
            comparison_summary = self._generate_comparison_summary(files_1, files_2)
            file_comparisons = self._compare_files(files_1, files_2, request.include_content)
            metrics_comparison = self._compare_metrics(files_1, files_2)
            recommendations = self._generate_recommendations(file_comparisons, metrics_comparison)
            
            return GenerationComparisonResponse(
                generation_1_id=generation_1_id,
                generation_2_id=generation_2_id,
                comparison_summary=comparison_summary,
                file_comparisons=file_comparisons,
                metrics_comparison=metrics_comparison,
                recommendations=recommendations
            )
            
        except Exception as e:
            logger.error(f"Generation comparison failed: {e}")
            raise ValueError(f"Comparison failed: {str(e)}")
    
    def _generate_comparison_summary(
        self, 
        files_1: Dict[str, str], 
        files_2: Dict[str, str]
    ) -> Dict[str, Any]:
        """Generate high-level comparison summary."""
        
        all_files = set(files_1.keys()) | set(files_2.keys())
        added_files = set(files_2.keys()) - set(files_1.keys())
        removed_files = set(files_1.keys()) - set(files_2.keys())
        common_files = set(files_1.keys()) & set(files_2.keys())
        
        modified_files = []
        for file_path in common_files:
            if files_1[file_path] != files_2[file_path]:
                modified_files.append(file_path)
        
        # Calculate size changes
        size_1 = sum(len(content) for content in files_1.values())
        size_2 = sum(len(content) for content in files_2.values())
        size_change = size_2 - size_1
        
        return {
            "total_files_compared": len(all_files),
            "files_in_generation_1": len(files_1),
            "files_in_generation_2": len(files_2),
            "added_files": len(added_files),
            "removed_files": len(removed_files),
            "modified_files": len(modified_files),
            "unchanged_files": len(common_files) - len(modified_files),
            "total_size_change": size_change,
            "size_change_percentage": (size_change / size_1 * 100) if size_1 > 0 else 0
        }
    
    def _compare_files(
        self, 
        files_1: Dict[str, str], 
        files_2: Dict[str, str], 
        include_content: bool
    ) -> List[FileComparison]:
        """Compare individual files between generations."""
        
        file_comparisons = []
        all_files = set(files_1.keys()) | set(files_2.keys())
        
        for file_path in sorted(all_files):
            if file_path in files_1 and file_path in files_2:
                # File exists in both
                content_1 = files_1[file_path]
                content_2 = files_2[file_path]
                
                if content_1 == content_2:
                    status = "unchanged"
                    content_diff = None
                    changes_summary = "No changes"
                else:
                    status = "modified"
                    size_change = len(content_2) - len(content_1)
                    
                    if include_content:
                        content_diff = self._generate_diff(content_1, content_2, file_path)
                    else:
                        content_diff = None
                    
                    changes_summary = self._generate_changes_summary(content_1, content_2)
                    
                    file_comparisons.append(FileComparison(
                        path=file_path,
                        status=status,
                        size_change=size_change,
                        content_diff=content_diff,
                        changes_summary=changes_summary
                    ))
            elif file_path in files_2:
                # File added in generation 2
                file_comparisons.append(FileComparison(
                    path=file_path,
                    status="added",
                    size_change=len(files_2[file_path]),
                    content_diff=f"+ {file_path} (new file)" if include_content else None,
                    changes_summary="New file added"
                ))
            else:
                # File removed in generation 2
                file_comparisons.append(FileComparison(
                    path=file_path,
                    status="removed",
                    size_change=-len(files_1[file_path]),
                    content_diff=f"- {file_path} (deleted)" if include_content else None,
                    changes_summary="File removed"
                ))
        
        return file_comparisons
    
    def _generate_diff(self, content_1: str, content_2: str, file_path: str) -> str:
        """Generate unified diff between two file contents."""
        
        lines_1 = content_1.splitlines(keepends=True)
        lines_2 = content_2.splitlines(keepends=True)
        
        diff = difflib.unified_diff(
            lines_1, 
            lines_2, 
            fromfile=f"a/{file_path}",
            tofile=f"b/{file_path}",
            lineterm=''
        )
        
        diff_lines = list(diff)
        
        # Limit diff size
        if len(diff_lines) > self.max_diff_lines:
            diff_lines = diff_lines[:self.max_diff_lines]
            diff_lines.append(f"\n... (diff truncated, {len(diff_lines)} more lines)")
        
        return ''.join(diff_lines)
    
    def _generate_changes_summary(self, content_1: str, content_2: str) -> str:
        """Generate a summary of changes between two contents."""
        
        lines_1 = content_1.splitlines()
        lines_2 = content_2.splitlines()
        
        added_lines = len(lines_2) - len(lines_1)
        
        # Count actual changes
        matcher = difflib.SequenceMatcher(None, lines_1, lines_2)
        changes = 0
        for tag, i1, i2, j1, j2 in matcher.get_opcodes():
            if tag != 'equal':
                changes += max(i2 - i1, j2 - j1)
        
        if added_lines > 0:
            return f"+{added_lines} lines, ~{changes} changes"
        elif added_lines < 0:
            return f"{added_lines} lines, ~{changes} changes"
        else:
            return f"~{changes} changes"
    
    def _compare_metrics(
        self, 
        files_1: Dict[str, str], 
        files_2: Dict[str, str]
    ) -> Dict[str, Any]:
        """Compare metrics between two generations."""
        
        def calculate_metrics(files: Dict[str, str]) -> Dict[str, Any]:
            total_lines = sum(len(content.splitlines()) for content in files.values())
            total_chars = sum(len(content) for content in files.values())
            
            # Count file types
            file_types = {}
            for file_path in files.keys():
                ext = Path(file_path).suffix.lower()
                file_types[ext] = file_types.get(ext, 0) + 1
            
            return {
                "total_files": len(files),
                "total_lines": total_lines,
                "total_characters": total_chars,
                "file_types": file_types,
                "avg_file_size": total_chars / len(files) if files else 0
            }
        
        metrics_1 = calculate_metrics(files_1)
        metrics_2 = calculate_metrics(files_2)
        
        return {
            "generation_1": metrics_1,
            "generation_2": metrics_2,
            "differences": {
                "files_change": metrics_2["total_files"] - metrics_1["total_files"],
                "lines_change": metrics_2["total_lines"] - metrics_1["total_lines"],
                "size_change": metrics_2["total_characters"] - metrics_1["total_characters"],
                "avg_file_size_change": metrics_2["avg_file_size"] - metrics_1["avg_file_size"]
            }
        }
    
    def _generate_recommendations(
        self, 
        file_comparisons: List[FileComparison], 
        metrics_comparison: Dict[str, Any]
    ) -> List[str]:
        """Generate recommendations based on comparison analysis."""
        
        recommendations = []
        
        # Analyze file changes
        added_files = [f for f in file_comparisons if f.status == "added"]
        removed_files = [f for f in file_comparisons if f.status == "removed"]
        modified_files = [f for f in file_comparisons if f.status == "modified"]
        
        if len(added_files) > len(modified_files):
            recommendations.append(
                "This generation adds many new files. Consider reviewing if all additions are necessary."
            )
        
        if len(removed_files) > 0:
            recommendations.append(
                f"This generation removes {len(removed_files)} files. Ensure this is intentional."
            )
        
        # Analyze size changes
        size_change = metrics_comparison["differences"]["size_change"]
        if size_change > 50000:  # 50KB
            recommendations.append(
                "Significant size increase detected. Consider optimizing code or assets."
            )
        elif size_change < -10000:  # 10KB reduction
            recommendations.append(
                "Good code reduction! This generation is more concise."
            )
        
        # Analyze file types
        gen1_types = set(metrics_comparison["generation_1"]["file_types"].keys())
        gen2_types = set(metrics_comparison["generation_2"]["file_types"].keys())
        
        new_types = gen2_types - gen1_types
        if new_types:
            recommendations.append(
                f"New file types introduced: {', '.join(new_types)}. Verify compatibility."
            )
        
        if not recommendations:
            recommendations.append("The changes look reasonable and well-structured.")
        
        return recommendations


# Create singleton instances
github_deployment_service = GitHubDeploymentService()
generation_comparison_service = GenerationComparisonService()